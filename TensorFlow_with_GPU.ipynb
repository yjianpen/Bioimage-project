{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yjianpen/Bioimage-project/blob/master/TensorFlow_with_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMce8muBqXQP"
      },
      "source": [
        "# Tensorflow with GPU\n",
        "\n",
        "This notebook provides an introduction to computing on a [GPU](https://cloud.google.com/gpu) in Colab. In this notebook you will connect to a GPU, and then run some basic TensorFlow operations on both the CPU and a GPU, observing the speedup provided by using the GPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM_8ELnJq_wd"
      },
      "source": [
        "## Enabling and testing the GPU\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll confirm that we can connect to the GPU with tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXnDmXR7RDr2",
        "outputId": "a7b436e8-d5c7-4e79-8df3-f36c49224578"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3fE7KmKRDsH"
      },
      "source": [
        "## Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "This example constructs a typical convolutional neural network layer over a\n",
        "random image and manually places the resulting ops on either the CPU or the GPU\n",
        "to compare execution speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y04m-jvKRDsJ",
        "outputId": "81833012-e63d-44f8-e683-d285c95eefa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "3.7838018520000105\n",
            "GPU (s):\n",
            "0.04772831899998664\n",
            "GPU speedup over CPU: 79x\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import math"
      ],
      "metadata": {
        "id": "y4NQhAz-piII"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Sky = [128,128,128]\n",
        "Building = [128,0,0]\n",
        "Pole = [192,192,128]\n",
        "Road = [128,64,128]\n",
        "Pavement = [60,40,222]\n",
        "Tree = [128,128,0]\n",
        "SignSymbol = [192,128,128]\n",
        "Fence = [64,64,128]\n",
        "Car = [64,0,128]\n",
        "Pedestrian = [64,64,0]\n",
        "Bicyclist = [0,128,192]\n",
        "Unlabelled = [0,0,0]\n",
        "\n",
        "COLOR_DICT = np.array([Sky, Building, Pole, Road, Pavement,\n",
        "                          Tree, SignSymbol, Fence, Car, Pedestrian, Bicyclist, Unlabelled])\n"
      ],
      "metadata": {
        "id": "R7et35xXpsDW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adjustData(img,mask,flag_multi_class,num_class):\n",
        "    if(flag_multi_class):\n",
        "        img = img / 255\n",
        "        mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n",
        "        new_mask = np.zeros(mask.shape + (num_class,))\n",
        "        for i in range(num_class):\n",
        "            #for one pixel in the image, find the class in mask and convert it into one-hot vector\n",
        "            #index = np.where(mask == i)\n",
        "            #index_mask = (index[0],index[1],index[2],np.zeros(len(index[0]),dtype = np.int64) + i) if (len(mask.shape) == 4) else (index[0],index[1],np.zeros(len(index[0]),dtype = np.int64) + i)\n",
        "            #new_mask[index_mask] = 1\n",
        "            new_mask[mask == i,i] = 1\n",
        "        new_mask = np.reshape(new_mask,(new_mask.shape[0],new_mask.shape[1]*new_mask.shape[2],new_mask.shape[3])) if flag_multi_class else np.reshape(new_mask,(new_mask.shape[0]*new_mask.shape[1],new_mask.shape[2]))\n",
        "        mask = new_mask\n",
        "    elif(np.max(img) > 1):\n",
        "        img = img / 255\n",
        "        mask = mask /255\n",
        "        mask[mask > 0.5] = 1\n",
        "        mask[mask <= 0.5] = 0\n",
        "    return (img,mask)"
      ],
      "metadata": {
        "id": "DmiM_AH0pw_i"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainGenerator_spectra(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode = \"grayscale\",\n",
        "                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
        "                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (960,720),seed = 1):\n",
        "    '''\n",
        "    can generate image and mask at the same time\n",
        "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
        "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
        "    '''\n",
        "    image_datagen = ImageDataGenerator(**aug_dict)\n",
        "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [image_folder],\n",
        "        class_mode = None,\n",
        "        color_mode = image_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = image_save_prefix,\n",
        "        seed = seed)\n",
        "    mask_generator = mask_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [mask_folder],\n",
        "        class_mode = None,\n",
        "        color_mode = mask_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = mask_save_prefix,\n",
        "        seed = seed)\n",
        "    train_generator = zip(image_generator, mask_generator)\n",
        "    for (img,mask) in train_generator:\n",
        "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
        "        ##img=img[0]\n",
        "        print(\"train img\",img.shape,\"label img\",mask.shape)\n",
        "        '''\n",
        "        plt.imshow(mask[0].reshape(960,720))\n",
        "        '''\n",
        "        yield (img,mask)\n",
        "\n"
      ],
      "metadata": {
        "id": "Yb_7hgxLp0vI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode = \"grayscale\",\n",
        "                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
        "                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (8,256),seed = 1):\n",
        "    '''\n",
        "    can generate image and mask at the same time\n",
        "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
        "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
        "    '''\n",
        "    image_datagen = ImageDataGenerator(**aug_dict)\n",
        "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [image_folder],\n",
        "        class_mode = None,\n",
        "        color_mode = image_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = image_save_prefix,\n",
        "        seed = seed)\n",
        "    mask_generator = mask_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [mask_folder],\n",
        "        class_mode = None,\n",
        "        color_mode = mask_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = mask_save_prefix,\n",
        "        seed = seed)\n",
        "    train_generator = zip(image_generator, mask_generator)\n",
        "    for (img,mask) in train_generator:\n",
        "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
        "        print(\"train img\",img.shape)\n",
        "        yield (img,mask)\n",
        "\n",
        "\n",
        "\n",
        "def testGenerator(test_path,num_image = 30,target_size = (256,256),flag_multi_class = False,as_gray = True):\n",
        "    for i in range(num_image):\n",
        "        img = io.imread(os.path.join(test_path,\"%d.png\"%i),as_gray = as_gray)\n",
        "        img = img / 255\n",
        "        img = trans.resize(img,target_size)\n",
        "        ##img = img [0]\n",
        "        img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img\n",
        "        img = np.reshape(img,(1,)+img.shape)\n",
        "        print(\"test img shape\",img.shape)\n",
        "        yield img\n",
        "\n",
        "def testGenerator_spectra(test_path,num_image = 30,target_size = (256,256),flag_multi_class = False,as_gray = True):\n",
        "    dirs=os.listdir(test_path)\n",
        "    print(\" test img 0\")\n",
        "    for i,d in enumerate(dirs):\n",
        "        '''\n",
        "        if \".tiff\" not in d:\n",
        "            continue\n",
        "        '''\n",
        "        ##img = Image.open(os.path.join(test_path,d))\n",
        "        img = plt.imread(os.path.join(test_path,d))\n",
        "        img = img / 255\n",
        "        img = trans.resize(img,target_size)\n",
        "        img = gray_img_arr(img)\n",
        "        ##mg = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img\n",
        "        print(\" test img 1\",img)\n",
        "        ##img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img\n",
        "        img = np.reshape(img,(1,)+img.shape)\n",
        "\n",
        "\n",
        "\n",
        "        ##print(\" test img\",img)\n",
        "        yield img\n",
        "\n",
        "def gray_img_arr(img):\n",
        "    print (\"Gray scale!\",img.shape)\n",
        "    shape=img.shape[:-1]\n",
        "    data=np.zeros(tuple(list(shape)+[1]))\n",
        "    for i in range(len(img)):\n",
        "        for j in range(len(img[0])):\n",
        "            data[i][j]=math.sqrt(img[i][j][0]**2+img[i][j][1]**2)\n",
        "    print (\"Gray scale!\",data.shape)\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def geneTrainNpy(image_path,mask_path,flag_multi_class = False,num_class = 2,image_prefix = \"image\",mask_prefix = \"mask\",image_as_gray = True,mask_as_gray = True):\n",
        "    image_name_arr = glob.glob(os.path.join(image_path,\"%s*.png\"%image_prefix))\n",
        "    image_arr = []\n",
        "    mask_arr = []\n",
        "    for index,item in enumerate(image_name_arr):\n",
        "        img = io.imread(item,as_gray = image_as_gray)\n",
        "        img = np.reshape(img,img.shape + (1,)) if image_as_gray else img\n",
        "        mask = io.imread(item.replace(image_path,mask_path).replace(image_prefix,mask_prefix),as_gray = mask_as_gray)\n",
        "        mask = np.reshape(mask,mask.shape + (1,)) if mask_as_gray else mask\n",
        "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
        "        image_arr.append(img)\n",
        "        mask_arr.append(mask)\n",
        "    image_arr = np.array(image_arr)\n",
        "    mask_arr = np.array(mask_arr)\n",
        "    return image_arr,mask_arr\n",
        "\n",
        "\n",
        "def labelVisualize(num_class,color_dict,img):\n",
        "    img = img[:,:,0] if len(img.shape) == 3 else img\n",
        "    img_out = np.zeros(img.shape + (3,))\n",
        "    for i in range(num_class):\n",
        "        img_out[img == i,:] = color_dict[i]\n",
        "    return img_out / 255\n",
        "\n",
        "\n",
        "\n",
        "def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
        "    for i,item in enumerate(npyfile):\n",
        "        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
        "        io.imsave(os.path.join(save_path,\"%d_predict.tif\"%i),img)\n",
        "\n",
        "def saveResult_spectra(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
        "    for i,item in enumerate(npyfile):\n",
        "      item=item.reshape(960,720)\n",
        "      print(\"saved image\",i,item)\n",
        "      plt.imsave(os.path.join(save_path,\"%d_predict.png\"%i),item,cmap=cm.gray)\n"
      ],
      "metadata": {
        "id": "8ypYbNi_p9O-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "##os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import MaxPooling2D as Maxping2D\n"
      ],
      "metadata": {
        "id": "keO0SBAbqLxs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unet(pretrained_weights = None,input_size = (256,256,1)):\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "    p1 = Maxping2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(p1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "    p2 = Maxping2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(p2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "    p3 = Maxping2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(p3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    p4 = Maxping2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(p4)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merg6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merg6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merg7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merg7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merg8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merg8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merg9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merg9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs = inputs, outputs = conv10)\n",
        "\n",
        "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "    #model.summary()\n",
        "\n",
        "    if(pretrained_weights):\n",
        "    \tmodel.load_weights(pretrained_weights)\n",
        "\n",
        "    return model\n",
        "\n",
        "def unet_spectra(pretrained_weights = None,input_size = (960,720,1)):\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "    p1 = Maxping2D(pool_size=(4, 3))(conv1)\n",
        "    conv2 = Conv2D(240, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(p1)\n",
        "    conv2 = Conv2D(240, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "    p2 = Maxping2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(p2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "    p3 = Maxping2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(p3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    p4 = Maxping2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(p4)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merg6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merg6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merg7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merg7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merg8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merg8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merg9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merg9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs = inputs, outputs = conv10)\n",
        "\n",
        "    model.compile(optimizer = Adam(lr = 1e-3), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "    #model.summary()\n",
        "\n",
        "    if(pretrained_weights):\n",
        "        model.load_weights(pretrained_weights)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "7Pn6LeAEqsgY"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "import os\n",
        "import tensorflow as tf\n",
        "##os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
        "\n",
        "data_gen_args = dict(rotation_range=0.2,\n",
        "                    width_shift_range=0.05,\n",
        "                    height_shift_range=0.05,\n",
        "                    shear_range=0.05,\n",
        "                    zoom_range=0.05,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode='nearest')\n",
        "'''\n",
        "myGene = trainGenerator(2,'data/membrane/train','image','label',data_gen_args,save_to_dir = None)\n",
        "\n",
        "model = unet()\n",
        "model_checkpoint = ModelCheckpoint('unet_membrane.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
        "model.fit(myGene,steps_per_epoch=3,epochs=1,callbacks=[model_checkpoint])\n",
        "\n",
        "testGene = testGenerator(\"data/membrane/test\")\n",
        "results = model.predict(testGene,verbose=1)\n",
        "saveResult(\"data/membrane/predict\",results)\n",
        "\n",
        "'''\n",
        "with tf.device('/device:GPU:0'):\n",
        "  root_dir=\"/content/drive/MyDrive/unet/\"\n",
        "  \n",
        "  myGene = trainGenerator_spectra(2,root_dir+'data/membrane/spectra/train','image','label',data_gen_args,save_to_dir = None,target_size = (960,720))\n",
        "  \n",
        "  model = unet(input_size = (960,720,1))\n",
        "  model_checkpoint = ModelCheckpoint(root_dir+'unet_membrane_spectra.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
        "  model.fit(myGene,steps_per_epoch=60,epochs=40,callbacks=[model_checkpoint])\n",
        "  '''\n",
        "  model = keras.models.load_model(root_dir+'unet_membrane_spectra.hdf5')\n",
        "  '''\n",
        "  testGene = testGenerator_spectra(root_dir+\"data/membrane/spectra/test\",target_size = (960,720))\n",
        "  results = model.predict(testGene,verbose=1)\n",
        "  print(\"results shape\",results.shape)\n",
        "  saveResult_spectra(root_dir+\"data/membrane/spectra/predict\",results)\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Jn8-4VMq1uH",
        "outputId": "986bd0fa-34fb-40fb-b62c-b8709c7af8e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 68 images belonging to 1 classes.\n",
            "Found 68 images belonging to 1 classes.\n",
            "train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "Epoch 1/40\n",
            "train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            " 1/60 [..............................] - ETA: 6:47 - loss: 0.8012 - accuracy: 0.6110train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            " 2/60 [>.............................] - ETA: 4:58 - loss: 0.7473 - accuracy: 0.6397train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            " 3/60 [>.............................] - ETA: 4:47 - loss: 0.7292 - accuracy: 0.6258train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            " 4/60 [=>............................] - ETA: 4:41 - loss: 0.7202 - accuracy: 0.6031train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            " 5/60 [=>............................] - ETA: 4:34 - loss: 0.7148 - accuracy: 0.6059train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            " 6/60 [==>...........................] - ETA: 4:29 - loss: 0.7112 - accuracy: 0.5849train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            " 7/60 [==>...........................] - ETA: 4:23 - loss: 0.7086 - accuracy: 0.5813train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            " 8/60 [===>..........................] - ETA: 4:18 - loss: 0.7067 - accuracy: 0.5740train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            " 9/60 [===>..........................] - ETA: 4:13 - loss: 0.7051 - accuracy: 0.5906train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "10/60 [====>.........................] - ETA: 4:08 - loss: 0.7039 - accuracy: 0.5892train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "11/60 [====>.........................] - ETA: 4:03 - loss: 0.7029 - accuracy: 0.6101train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "12/60 [=====>........................] - ETA: 3:57 - loss: 0.7021 - accuracy: 0.6025train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "13/60 [=====>........................] - ETA: 3:52 - loss: 0.7014 - accuracy: 0.6138train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "14/60 [======>.......................] - ETA: 3:47 - loss: 0.7008 - accuracy: 0.6037train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "15/60 [======>.......................] - ETA: 3:42 - loss: 0.7003 - accuracy: 0.6170train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "16/60 [=======>......................] - ETA: 3:37 - loss: 0.6998 - accuracy: 0.6211train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "17/60 [=======>......................] - ETA: 3:32 - loss: 0.6994 - accuracy: 0.6346train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "18/60 [========>.....................] - ETA: 3:27 - loss: 0.6991 - accuracy: 0.6291train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "19/60 [========>.....................] - ETA: 3:22 - loss: 0.6987 - accuracy: 0.6233train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "20/60 [=========>....................] - ETA: 3:17 - loss: 0.6985 - accuracy: 0.6148train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "21/60 [=========>....................] - ETA: 3:12 - loss: 0.6982 - accuracy: 0.6019train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "22/60 [==========>...................] - ETA: 3:07 - loss: 0.6980 - accuracy: 0.6061train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "23/60 [==========>...................] - ETA: 3:02 - loss: 0.6977 - accuracy: 0.6117train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "24/60 [===========>..................] - ETA: 2:57 - loss: 0.6975 - accuracy: 0.6137train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "25/60 [===========>..................] - ETA: 2:52 - loss: 0.6974 - accuracy: 0.6138train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "26/60 [============>.................] - ETA: 2:47 - loss: 0.6972 - accuracy: 0.6182train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "27/60 [============>.................] - ETA: 2:42 - loss: 0.6970 - accuracy: 0.6237train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "28/60 [=============>................] - ETA: 2:37 - loss: 0.6969 - accuracy: 0.6264train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "29/60 [=============>................] - ETA: 2:32 - loss: 0.6967 - accuracy: 0.6299train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "30/60 [==============>...............] - ETA: 2:27 - loss: 0.6966 - accuracy: 0.6373train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "31/60 [==============>...............] - ETA: 2:22 - loss: 0.6964 - accuracy: 0.6414train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "32/60 [===============>..............] - ETA: 2:17 - loss: 0.6963 - accuracy: 0.6461train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "33/60 [===============>..............] - ETA: 2:12 - loss: 0.6962 - accuracy: 0.6502train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "34/60 [================>.............] - ETA: 2:07 - loss: 0.6961 - accuracy: 0.6474train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "35/60 [================>.............] - ETA: 2:02 - loss: 0.6960 - accuracy: 0.6480train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "36/60 [=================>............] - ETA: 1:58 - loss: 0.6959 - accuracy: 0.6451train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "37/60 [=================>............] - ETA: 1:53 - loss: 0.6958 - accuracy: 0.6489train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "38/60 [==================>...........] - ETA: 1:48 - loss: 0.6957 - accuracy: 0.6489train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "39/60 [==================>...........] - ETA: 1:43 - loss: 0.6956 - accuracy: 0.6502train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "40/60 [===================>..........] - ETA: 1:38 - loss: 0.6955 - accuracy: 0.6517train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "41/60 [===================>..........] - ETA: 1:33 - loss: 0.6955 - accuracy: 0.6497train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "42/60 [====================>.........] - ETA: 1:28 - loss: 0.6954 - accuracy: 0.6448train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "43/60 [====================>.........] - ETA: 1:23 - loss: 0.6953 - accuracy: 0.6459train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "44/60 [=====================>........] - ETA: 1:18 - loss: 0.6953 - accuracy: 0.6448train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "45/60 [=====================>........] - ETA: 1:13 - loss: 0.6952 - accuracy: 0.6488train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "46/60 [======================>.......] - ETA: 1:08 - loss: 0.6951 - accuracy: 0.6471train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "47/60 [======================>.......] - ETA: 1:03 - loss: 0.6951 - accuracy: 0.6406train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "48/60 [=======================>......] - ETA: 58s - loss: 0.6951 - accuracy: 0.6405 train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "49/60 [=======================>......] - ETA: 54s - loss: 0.6950 - accuracy: 0.6404train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "50/60 [========================>.....] - ETA: 49s - loss: 0.6949 - accuracy: 0.6420train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "51/60 [========================>.....] - ETA: 44s - loss: 0.6949 - accuracy: 0.6437train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "52/60 [=========================>....] - ETA: 39s - loss: 0.6949 - accuracy: 0.6394train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "53/60 [=========================>....] - ETA: 34s - loss: 0.6948 - accuracy: 0.6426train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "54/60 [==========================>...] - ETA: 29s - loss: 0.6948 - accuracy: 0.6431train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "55/60 [==========================>...] - ETA: 24s - loss: 0.6947 - accuracy: 0.6456train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "56/60 [===========================>..] - ETA: 19s - loss: 0.6947 - accuracy: 0.6443train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "57/60 [===========================>..] - ETA: 14s - loss: 0.6946 - accuracy: 0.6475train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "58/60 [============================>.] - ETA: 9s - loss: 0.6946 - accuracy: 0.6478 train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "59/60 [============================>.] - ETA: 4s - loss: 0.6945 - accuracy: 0.6487train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.6945 - accuracy: 0.6465\n",
            "Epoch 1: loss improved from inf to 0.69450, saving model to /content/drive/MyDrive/unet/unet_membrane_spectra.hdf5\n",
            "60/60 [==============================] - 298s 5s/step - loss: 0.6945 - accuracy: 0.6465\n",
            "Epoch 2/40\n",
            "train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            " 1/60 [..............................] - ETA: 4:48 - loss: 0.6928 - accuracy: 0.5447train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            " 2/60 [>.............................] - ETA: 4:44 - loss: 0.6929 - accuracy: 0.5452train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            " 3/60 [>.............................] - ETA: 4:38 - loss: 0.6922 - accuracy: 0.6563train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            " 4/60 [=>............................] - ETA: 4:33 - loss: 0.6918 - accuracy: 0.6938train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            " 5/60 [=>............................] - ETA: 4:29 - loss: 0.6919 - accuracy: 0.6680train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            " 6/60 [==>...........................] - ETA: 4:24 - loss: 0.6918 - accuracy: 0.6841train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            " 7/60 [==>...........................] - ETA: 4:19 - loss: 0.6919 - accuracy: 0.6684train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            " 8/60 [===>..........................] - ETA: 4:14 - loss: 0.6919 - accuracy: 0.6585train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            " 9/60 [===>..........................] - ETA: 4:09 - loss: 0.6921 - accuracy: 0.6424train img (2, 960, 720, 1) label img (2, 960, 720, 1)\n",
            "10/60 [====>.........................] - ETA: 4:05 - loss: 0.6919 - accuracy: 0.6644"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ROn3TqClUzTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "80lu-8vynWDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os import listdir\n",
        "print(os.listdir())"
      ],
      "metadata": {
        "id": "6OinFDQinXYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import JSON\n",
        "from google.colab import output\n",
        "from subprocess import getoutput\n",
        "import os\n",
        "\n",
        "def shell(command):\n",
        "  if command.startswith('cd'):\n",
        "    path = command.strip().split(maxsplit=1)[1]\n",
        "    os.chdir(path)\n",
        "    return JSON([''])\n",
        "  return JSON([getoutput(command)])\n",
        "output.register_callback('shell', shell)"
      ],
      "metadata": {
        "id": "vi6g-p-6VMYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<div id=colab_shell></div>\n",
        "<script src=\"https://code.jquery.com/jquery-latest.js\"></script>\n",
        "<script src=\"https://cdn.jsdelivr.net/npm/jquery.terminal/js/jquery.terminal.min.js\"></script>\n",
        "<link href=\"https://cdn.jsdelivr.net/npm/jquery.terminal/css/jquery.terminal.min.css\" rel=\"stylesheet\"/>\n",
        "<script>\n",
        "  $('#colab_shell').terminal(async function(command) {\n",
        "      if (command !== '') {\n",
        "          try {\n",
        "              let res = await google.colab.kernel.invokeFunction('shell', [command])\n",
        "              let out = res.data['application/json'][0]\n",
        "              this.echo(new String(out))\n",
        "          } catch(e) {\n",
        "              this.error(new String(e));\n",
        "          }\n",
        "      } else {\n",
        "          this.echo('');\n",
        "      }\n",
        "  }, {\n",
        "      greetings: 'Welcome to Colab Shell',\n",
        "      name: 'colab_shell',\n",
        "      height: 450,\n",
        "      prompt: 'colab > '\n",
        "  });"
      ],
      "metadata": {
        "id": "aGv4ticLVOgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Fys3INUhnk1v"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TensorFlow with GPU",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}